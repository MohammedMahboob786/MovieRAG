{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBgmXW6FJ7px",
        "outputId": "8c8b4df1-231d-4f01-f925-e90d5bca564e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/Colab Notebooks/colab_env/lib/python3.10/site-packages\")\n",
        "sys.path.append(\"/content/drive/MyDrive/Colab Notebooks/colab_env_/lib/python3.10/site-packages\")"
      ],
      "metadata": {
        "id": "Ci3EGp91NZCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "vld4T6kvNY-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Increase the field size limit\n",
        "csv.field_size_limit(sys.maxsize)\n",
        "\n",
        "loader = CSVLoader(file_path='/content/drive/MyDrive/Colab Notebooks/CSV data/part_2.csv')\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "ZacNbo_HNY8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "\n",
        "chunks = text_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "MX_AUyfBNY5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of Documents:\", len(data))\n",
        "print()\n",
        "print(\"Number of Chunks:\", len(chunks))"
      ],
      "metadata": {
        "id": "RGeZ-hjwNY2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_chunks = 1570007\n",
        "\n",
        "# Define the size of each chunk\n",
        "chunk_size = 40000\n",
        "\n",
        "# Create a list to hold the split chunks\n",
        "chunked_list = []\n",
        "\n",
        "for i in range(0, number_of_chunks, chunk_size):\n",
        "    chunked_list.append(chunks[i:i + chunk_size])"
      ],
      "metadata": {
        "id": "7-69SI8HNYzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total=0\n",
        "# Verify the size of each chunk\n",
        "for i, chunk in enumerate(chunked_list):\n",
        "    print(f\"Chunk {i + 1} Size: {len(chunk)}\")\n",
        "    total +=len(chunk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTr3evRaNYwd",
        "outputId": "0f0e8af0-1905-47d3-cc89-b5c483626ae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk 1 Size: 40000\n",
            "Chunk 2 Size: 40000\n",
            "Chunk 3 Size: 40000\n",
            "Chunk 4 Size: 40000\n",
            "Chunk 5 Size: 40000\n",
            "Chunk 6 Size: 40000\n",
            "Chunk 7 Size: 40000\n",
            "Chunk 8 Size: 40000\n",
            "Chunk 9 Size: 40000\n",
            "Chunk 10 Size: 40000\n",
            "Chunk 11 Size: 40000\n",
            "Chunk 12 Size: 40000\n",
            "Chunk 13 Size: 40000\n",
            "Chunk 14 Size: 40000\n",
            "Chunk 15 Size: 40000\n",
            "Chunk 16 Size: 40000\n",
            "Chunk 17 Size: 40000\n",
            "Chunk 18 Size: 40000\n",
            "Chunk 19 Size: 40000\n",
            "Chunk 20 Size: 40000\n",
            "Chunk 21 Size: 40000\n",
            "Chunk 22 Size: 40000\n",
            "Chunk 23 Size: 40000\n",
            "Chunk 24 Size: 40000\n",
            "Chunk 25 Size: 40000\n",
            "Chunk 26 Size: 40000\n",
            "Chunk 27 Size: 40000\n",
            "Chunk 28 Size: 40000\n",
            "Chunk 29 Size: 40000\n",
            "Chunk 30 Size: 40000\n",
            "Chunk 31 Size: 40000\n",
            "Chunk 32 Size: 40000\n",
            "Chunk 33 Size: 40000\n",
            "Chunk 34 Size: 40000\n",
            "Chunk 35 Size: 40000\n",
            "Chunk 36 Size: 40000\n",
            "Chunk 37 Size: 40000\n",
            "Chunk 38 Size: 40000\n",
            "Chunk 39 Size: 40000\n",
            "Chunk 40 Size: 10007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "\n",
        "# # Step 2: Define the path where you want to save the embeddings model\n",
        "# file_path = '/content/drive/My Drive/Copy of chunked_list.pkl'\n",
        "\n",
        "# # Step 3: Save embeddings model to the specified path\n",
        "# with open(file_path, 'wb') as file:\n",
        "#     pickle.dump(chunked_list, file)"
      ],
      "metadata": {
        "id": "9rNVNrplTTHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For 15% of the entire subtitle data. I should have 8,00,000 chunks."
      ],
      "metadata": {
        "id": "NWVQvXn3RRz-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QfA4EQiKDfb"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/Colab Notebooks/colab_env/lib/python3.10/site-packages\")\n",
        "sys.path.append(\"/content/drive/MyDrive/Colab Notebooks/colab_env_/lib/python3.10/site-packages\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N10QcHimLSlJ",
        "outputId": "8c257dde-9f30-4963-9256-518d0a60f84a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/Copy of chunked_list.pkl'\n",
        "with open(file_path, 'rb') as file:\n",
        "    chunked_list = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "3X_amS8iM7Pb",
        "outputId": "071c7938-b98c-4abe-99ac-18e074c70503",
        "collapsed": true
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-42443d9be04b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"thenlper/gte-small\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_huggingface\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHuggingFaceEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0membeddings_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHuggingFaceEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/Colab Notebooks/colab_env_/lib/python3.10/site-packages/langchain_huggingface/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_huggingface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatHuggingFace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m from langchain_huggingface.embeddings import (\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mHuggingFaceEmbeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mHuggingFaceEndpointEmbeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m/content/drive/MyDrive/Colab Notebooks/colab_env_/lib/python3.10/site-packages/langchain_huggingface/embeddings/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_huggingface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhuggingface\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHuggingFaceEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m from langchain_huggingface.embeddings.huggingface_endpoint import (\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mHuggingFaceEndpointEmbeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model_name = \"thenlper/gte-small\"\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "embeddings_model = HuggingFaceEmbeddings(model_name=model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcsckurmfTKq",
        "outputId": "1b297c00-42e4-4abd-8c28-9ba1b1cec416"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
              "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n",
              "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
              "  (2): Normalize()\n",
              "), model_name='thenlper/gte-small', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZFcni0kN_7s"
      },
      "outputs": [],
      "source": [
        "# import pickle\n",
        "\n",
        "# # Step 2: Define the path where you want to save the embeddings model\n",
        "# file_path = '/content/drive/My Drive/embeddings model.pkl'\n",
        "\n",
        "# # Step 3: Save embeddings model to the specified path\n",
        "# with open(file_path, 'wb') as file:\n",
        "#     pickle.dump(embeddings_model, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoWhZjPXOm39",
        "outputId": "01571e5b-c569-4eb8-c784-650d0a80281a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/colab_env_/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "file_path = '/content/drive/My Drive/embeddings model.pkl'\n",
        "with open(file_path, 'rb') as file:\n",
        "    embeddings_model = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hp562r8FMdSl"
      },
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma\n",
        "\n",
        "CHROMA_PATH = \"/content/drive/MyDrive/DataBase2\"\n",
        "\n",
        "# Load it into Chroma\n",
        "db = Chroma(collection_name=\"vector_database\",\n",
        "            embedding_function=embeddings_model,\n",
        "            persist_directory=CHROMA_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "kP2T6vXikdty"
      },
      "outputs": [],
      "source": [
        "db.add_documents(chunked_list[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "collapsed": true,
        "id": "cy4WZ-35lPiA"
      },
      "outputs": [],
      "source": [
        "db.add_documents(chunked_list[1])\n",
        "db.add_documents(chunked_list[2])\n",
        "db.add_documents(chunked_list[3])\n",
        "db.add_documents(chunked_list[4])\n",
        "db.add_documents(chunked_list[5])\n",
        "db.add_documents(chunked_list[6])\n",
        "db.add_documents(chunked_list[7])\n",
        "db.add_documents(chunked_list[8])\n",
        "db.add_documents(chunked_list[9])\n",
        "db.add_documents(chunked_list[10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLe4Y_kUT-ns"
      },
      "outputs": [],
      "source": [
        "db.add_documents(chunked_list[11])\n",
        "db.add_documents(chunked_list[12])\n",
        "db.add_documents(chunked_list[13])\n",
        "db.add_documents(chunked_list[14])\n",
        "db.add_documents(chunked_list[15])\n",
        "db.add_documents(chunked_list[16])\n",
        "db.add_documents(chunked_list[17])\n",
        "db.add_documents(chunked_list[18])\n",
        "db.add_documents(chunked_list[19])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYsc-Xq6lP8f"
      },
      "outputs": [],
      "source": [
        "print(len(db.get()[\"ids\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "II5Vi_mzIlH6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9b4xVFO5U8Bf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iB1J6WKyPn_g"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}